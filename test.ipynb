{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os \n",
    "from path import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_off(file):\n",
    "    if 'OFF' != file.readline().strip():\n",
    "        raise('Not a valid OFF header')\n",
    "    n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])\n",
    "    verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n",
    "    faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n",
    "    return verts, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudData(Dataset):\n",
    "    def __init__(self, root_dir, valid=False, folder=\"train\"):\n",
    "        self.root_dir = root_dir\n",
    "        folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n",
    "        self.classes = {folder: i for i, folder in enumerate(folders)}\n",
    "        self.valid = valid\n",
    "        self.files = []\n",
    "        for category in self.classes.keys():\n",
    "            new_dir = root_dir/Path(category)/folder\n",
    "            for file in os.listdir(new_dir):\n",
    "                if file.endswith('.off'):\n",
    "                    sample = {}\n",
    "                    sample['pcd_path'] = new_dir/file\n",
    "                    sample['category'] = category\n",
    "                    self.files.append(sample)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pcd_path = self.files[idx]['pcd_path']\n",
    "        category = self.files[idx]['category']\n",
    "        with open(pcd_path, 'r') as f:\n",
    "            pointcloud = self.__preproc__(f)\n",
    "        return {'pointcloud': pointcloud, \n",
    "                'category': self.classes[category]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"ModelNet10\")\n",
    "test_dataset = PointCloudData(path, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "for i in range(99,100, 1):\n",
    "    filename = \"/home/akshay/Deep_Closest_Point/dcpv-1_org/sample_input_\" + str(i) + \".npy\"\n",
    "    np_array = np.load(filename)\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(np_array)\n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "    filename = \"/home/akshay/Deep_Closest_Point/dcpv-1_org/sample_output\" + str(i) + \".npy\"\n",
    "    np_array = np.load(filename)\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(np_array)\n",
    "    o3d.visualization.draw_geometries([pcd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idgcn import ConvBNList, find_neighbors, get_graph_feature\n",
    "import torch\n",
    "from pointnet2_ops.pointnet2_utils import grouping_operation\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004763603210449219\n",
      "0.00010132789611816406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 6, 1024, 20]), torch.Size([64, 3, 1024, 20]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((64, 3, 1024)).cuda()\n",
    "y = find_neighbors(x)\n",
    "y = y.type(torch.int32).contiguous().cuda()\n",
    "start_t = time.time()\n",
    "z = get_graph_feature(x, y)\n",
    "print(time.time()-start_t)\n",
    "start_t = time.time()\n",
    "z2 = grouping_operation(x.cuda(), y.cuda())\n",
    "print(time.time()-start_t)\n",
    "z.shape, z2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_BN_List(\n",
      "  (layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "agg_fn = lambda x: x\n",
    "layer1 = ConvBNList([32, 64], agg_fn, 128)\n",
    "print(layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseGCN(\n",
      "  (conv_bn): ConvBNList(\n",
      "    (layers): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 128, 1024, 20])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "import torch\n",
    "from idgcn import DenseGCN\n",
    "layer = DenseGCN(32, 128)\n",
    "print(layer)\n",
    "x = torch.randn((8, 32, 1024, 20))\n",
    "y = layer(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import torch \n",
    "from idgcn import InceptionDenseGCN\n",
    "layer = InceptionDenseGCN(128, 256).cuda()\n",
    "x = torch.randn((3, 128, 1024)).cuda()\n",
    "print(layer)\n",
    "y = layer(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35939550399780273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 1024])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import time \n",
    "from idgcn import FeatureExtractor\n",
    "layer = FeatureExtractor(features_dim=[3, 128, 256, 256]).cuda()\n",
    "x = torch.randn((8, 3, 1024)).cuda()\n",
    "start_t = time.time()\n",
    "y = layer(x)\n",
    "print(time.time() - start_t)\n",
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0014646053314208984\n",
      "309632\n"
     ]
    }
   ],
   "source": [
    "from model import DGCNN\n",
    "import time\n",
    "model = DGCNN().cuda()\n",
    "x = torch.randn((8, 3, 1024)).cuda()\n",
    "start_t = time.time()\n",
    "y = model(x)\n",
    "print(time.time() - start_t)\n",
    "x = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f61743acd3d0ddd231ad2d48bb2b41d7113834f365e261c46f0953c3259a124"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('materials2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
