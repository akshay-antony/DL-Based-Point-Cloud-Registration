{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9840, 2048, 3)\n",
      "(2468, 2048, 3)\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# Part of the code is referred from: https://github.com/charlesq34/pointnet\n",
    "\n",
    "def download():\n",
    "    BASE_DIR = os.getcwd()\n",
    "    DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "    if not os.path.exists(DATA_DIR):\n",
    "        os.mkdir(DATA_DIR)\n",
    "    if not os.path.exists(os.path.join(DATA_DIR, 'modelnet40_ply_hdf5_2048')):\n",
    "        www = 'https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip'\n",
    "        zipfile = os.path.basename(www)\n",
    "        os.system('wget %s; unzip %s' % (www, zipfile))\n",
    "        os.system('mv %s %s' % (zipfile[:-4], DATA_DIR))\n",
    "        os.system('rm %s' % (zipfile))\n",
    "\n",
    "\n",
    "def load_data(partition):\n",
    "    download()\n",
    "    BASE_DIR = os.getcwd()\n",
    "    DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "    all_data = []\n",
    "    all_label = []\n",
    "    for h5_name in glob.glob(os.path.join(DATA_DIR, 'modelnet40_ply_hdf5_2048', 'ply_data_%s*.h5' % partition)):\n",
    "        \n",
    "        with h5py.File(h5_name, \"r\") as f:\n",
    "            data = f['data'][:].astype('float32')\n",
    "            label = f['label'][:].astype('int64')\n",
    "            f.close()\n",
    "            all_data.append(data)\n",
    "            all_label.append(label)\n",
    "    \n",
    "    all_data = np.concatenate(all_data, axis=0)\n",
    "    all_label = np.concatenate(all_label, axis=0)\n",
    "\n",
    "    return all_data, all_label\n",
    "\n",
    "\n",
    "def translate_pointcloud(pointcloud):\n",
    "    xyz1 = np.random.uniform(low=2. / 3., high=3. / 2., size=[3])\n",
    "    xyz2 = np.random.uniform(low=-0.2, high=0.2, size=[3])\n",
    "\n",
    "    translated_pointcloud = np.add(np.multiply(pointcloud, xyz1), xyz2).astype('float32')\n",
    "    return translated_pointcloud\n",
    "\n",
    "\n",
    "def jitter_pointcloud(pointcloud, sigma=0.01, clip=0.05):\n",
    "    N, C = pointcloud.shape\n",
    "    pointcloud += np.clip(sigma * np.random.randn(N, C), -1 * clip, clip)\n",
    "    return pointcloud\n",
    "\n",
    "\n",
    "class ModelNet40(Dataset):\n",
    "    def __init__(self, num_points, partition='train', gaussian_noise=False, unseen=False, factor=4):\n",
    "        self.data, self.label = load_data(partition)\n",
    "        self.num_points = num_points\n",
    "        self.partition = partition\n",
    "        self.gaussian_noise = gaussian_noise\n",
    "        self.unseen = unseen\n",
    "        self.label = self.label.squeeze()\n",
    "        self.factor = factor\n",
    "        if self.unseen:\n",
    "            ######## simulate testing on first 20 categories while training on last 20 categories\n",
    "            if self.partition == 'test':\n",
    "                self.data = self.data[self.label>=20]\n",
    "                self.label = self.label[self.label>=20]\n",
    "            elif self.partition == 'train':\n",
    "                self.data = self.data[self.label<20]\n",
    "                self.label = self.label[self.label<20]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        pointcloud = self.data[item][:self.num_points]\n",
    "        if self.gaussian_noise:\n",
    "            pointcloud = jitter_pointcloud(pointcloud)\n",
    "        if self.partition != 'train':\n",
    "            np.random.seed(item)\n",
    "        anglex = np.random.uniform() * np.pi / self.factor\n",
    "        angley = np.random.uniform() * np.pi / self.factor\n",
    "        anglez = np.random.uniform() * np.pi / self.factor\n",
    "\n",
    "        cosx = np.cos(anglex)\n",
    "        cosy = np.cos(angley)\n",
    "        cosz = np.cos(anglez)\n",
    "        sinx = np.sin(anglex)\n",
    "        siny = np.sin(angley)\n",
    "        sinz = np.sin(anglez)\n",
    "        Rx = np.array([[1, 0, 0],\n",
    "                        [0, cosx, -sinx],\n",
    "                        [0, sinx, cosx]])\n",
    "        Ry = np.array([[cosy, 0, siny],\n",
    "                        [0, 1, 0],\n",
    "                        [-siny, 0, cosy]])\n",
    "        Rz = np.array([[cosz, -sinz, 0],\n",
    "                        [sinz, cosz, 0],\n",
    "                        [0, 0, 1]])\n",
    "        R_ab = Rx.dot(Ry).dot(Rz)\n",
    "        R_ba = R_ab.T\n",
    "        translation_ab = np.array([np.random.uniform(-0.5, 0.5), np.random.uniform(-0.5, 0.5),\n",
    "                                   np.random.uniform(-0.5, 0.5)])\n",
    "        translation_ba = -R_ba.dot(translation_ab)\n",
    "\n",
    "        pointcloud1 = pointcloud.T\n",
    "\n",
    "        rotation_ab = Rotation.from_euler('zyx', [anglez, angley, anglex])\n",
    "        pointcloud2 = rotation_ab.apply(pointcloud1.T).T + np.expand_dims(translation_ab, axis=1)\n",
    "\n",
    "        euler_ab = np.asarray([anglez, angley, anglex])\n",
    "        euler_ba = -euler_ab[::-1]\n",
    "\n",
    "        pointcloud1 = np.random.permutation(pointcloud1.T).T\n",
    "        pointcloud2 = np.random.permutation(pointcloud2.T).T\n",
    "\n",
    "        return pointcloud1.astype('float32'), pointcloud2.astype('float32'), R_ab.astype('float32'), \\\n",
    "               translation_ab.astype('float32'), R_ba.astype('float32'), translation_ba.astype('float32'), \\\n",
    "               euler_ab.astype('float32'), euler_ba.astype('float32')\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train = ModelNet40(1024)\n",
    "    test = ModelNet40(1024, 'test')\n",
    "    for data in train:\n",
    "        print(len(data))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\pardh\\\\0_Deep Learning\\\\Project\\\\dcp'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61096a4dd417a00febe40c9ffb1ac21f58e1b315410c331e61915ea3cc9ba0e4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('DeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
